
During this thesis, we have discovered that the area of software testing
is a very broad subject. The literature study disclosed several
interesting topics among we could only consider a few. Some topics was
also planned to be covered in this thesis, but was later removed. This
chapter discusses a few ideas on ways to further extend the work that
has been considered in this thesis.\\


\subsection{Ways of writing integration tests}

As discussed in \fref{sec:integration_testing}, there are several
opinions about integration tests and whether or not they should be
written as  integrated tests or not. We mentioned the concept of
contract tests as proposed by \citet{video:integrated_scam}, but we have
not been able to test this concept in practice. It would be intriguing
to see how such approaches could be used. Is this procedure useful in
practice? How is the fault detection rate affected by the way of writing
these tests? Does the choice of programming language have a large impact
on how useful contract tests are?\\


\subsection{Evaluation of tests with mutation testing}

In \fref{sec:theory_mutation} and \ref{sec:choices_mutation}, we discuss
the theory behind mutation testing and some of our efforts on this
subject. Our results were however not very successful. We believe that
mutation testing is a very interesting subject with plenty of research
basis. It could be rewarding to dig further on this subject, and see if
there would be possible to create more robust and production-ready
framework for mutation testing of web applications. Is it possible to
reduce to number of equivalent mutants and total number of mutants, so
that  this technique can be applied to larger parts of the code base?
How does the level of testing affect the mutation testing results? What
needs to be done in order to create a robust framework for mutation
testing which is really useful in a real web application?\\


\subsection{Automatic test generation}

Automated test generation is the theory behind how tests can be
generated automatically. This area was initially a part of this thesis,
but was removed in order to narrow down the scope. One approach is to
examine the code and find test cases in order to achieve good test
coverage, as discussed in \fref{sec:theory_coverage}, and another
approach is to simply test random input data. There are already quite
many scientific articles on this topic, but it would be interesting to
see how this would work in this specific environment. Is it possible to
automatically generate useful test cases for a Ruby application? How can
automated test generation be combined with the use of a test-driven
development methodology? How is the quality metrics (i.e. test coverage,
running time) affected by using generated tests?\\


\subsection{Continuous testing and deployment}

One purpose of this thesis is to examine how software testing can be
used in order to prevent bugs in production code. Even if tests exist,
there is however a chance that tests are accidentally removed, not run
before deployment, or not tested in all browser versions. One way to
mitigate the chance of this could be to run tests continuously, and
perhaps automatically deploy changes as soon as all tests passes. It
would be interesting to see how this can be achieved in practice in this
specific environment. How can the risk of bugs slipping out in
production environment be reduced? Does these changes to the way of
running tests change the importance of quality metrics? Is it possible
to automatically measure quality metrics when tests are run
continuously?\\

