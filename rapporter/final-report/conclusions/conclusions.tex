
This chapter presents some final thoughts and reflections on the results
and summarizes the previously discussed conclusions. We also present a
summary of our proposed solution for testing a web application.\\

\section{General conclusions}

\begin{itemize}

\item  Working with the chosen testing frameworks (RSpec and Jasmine
with the Karma test runner) has worked very well for testing this
particular application. We believe that it would also work very well for
testing most similar web applications.\\

\item The experience of using test-driven development as well as some
topics originating from behavior-driven development has been pleasant.
While this is a subjective opinion, we believe that this might be the
case for many other software developers and for other projects as well.
We have also found that the newly implemented functionality is well
tested and that its test efficiency is high, which may be another
benefit from using these methodologies. Writing tests using a
ubiquitous language is however not beneficial for this particular
application.\\

\item The combination of many integration- and unit-tests, complemented
by a few browser tests was successful for this project. It might however
be hard to determine the best level of testing for certain
functionality.\\

The level of testing and the combination of different kinds of tests
basically depends on the application. It is neither possible to say that
writing higher-level unit- or integration- test is generally worse
than writing lower-level unit tests, nor the contrary. Using browser
tests as the primary testing method for most projects is probably not
the best solution, however.\\

\item A test suite can speed up significantly by using factory objects
rather than using fixtures or manually create data when the test suite
is initialized. While these tests still are not in the same magnitude of
speed as the low-level unit tests written for the client side, they are
still fast enough to be usable for using test-driven development
methodologies.\\

\item Using metrics for test efficiency such as test coverage is usable
for finding parts of the code that lacks testing, in order to make tests
better. We believe that statement test coverage is usable, even if
branch coverage is more helpful and returns more fair coverage
percentages. The increased test efficiency could possibly lead to
finding more software defects due to more efficient tests, but we have
not found any defects of this type by using test efficiency metrics in
this project.\\

\end{itemize}


\section{Suggested solution for testing a web application}

For a web application with at least some amount of client-side and
server-side code, we would recommend unit-testing for the client as well
as the server. In addition, system-level browser tests should be used.
Most of the written tests should be on unit- or integration- level
tests, but the exact proportions depend on the application.\\

We would recommend applications that use Javascript or CoffeeScript on
the client side to use the Jasmine testing framework together with the
Karma test runner. For testing the client-side in Rails projects,
Teaspoon could be an alternative to Karma. See \fref{sec:js_test} for
more discussion on the subject.\\

A server side written Ruby on Rails could be tested using RSpec, with
factory\_girl for generating test data. Controllers can preferably be
tested using higher-level tests, while model instance methods often can
be tested using lower-level unit tests. See \fref{sec:ruby_test} for
more details on Rails testing frameworks.\\

Selenium is highly useful for system-level tests. Using a higher-level
framework such as Capybara rather than using Selenium directly is
recommended. The page object pattern should be used. SitePrism is useful
for this purpose. See \fref{sec:choices_browser} for more information
about these frameworks.\\
