
During this thesis, we have discovered that the area of software testing
is a very broad subject. The literature study disclosed several
interesting topics, among we could only consider a few. This chapter
discusses a few ideas on ways to further extend the work which has been
considered in this thesis.\\


\section{Automatic test generation}

 Automated test generation is the theory behind how tests can be
generated automatically.This area was initially a part of this thesis,
but was removed in order to narrow down the scope. One approach is to
examine the code and find test cases in order to achieve good test
coverage, as discussed in \fref{sec:theory_coverage}, an another
approach is to simply test random input data. There are already quite
many scientific articles on this topic, but it would be interesting to
see how this would work in this specific environment. Is it possible to
automatically generate useful test cases for a Ruby application? How can
automated test generation be combined with the use of a test-driven
development methodology? How is the quality metrics (i.e. test coverage,
running time) affected by using generated tests?\\


\section{Continuous testing and deployment}

One purpose of this thesis is to examine how software testing can be
used in order to prevent bugs in production code. Even if tests exists,
there is however a chance that tests are accidentally removed, not run
before deployment, or not tested in all browser versions. One way to
mitigate the chance of this could be to run tests continuously, and
perhaps automatically deploy changes as soon as all tests passes. It
would be interesting to see how this can be achieved in practice in this
specific environment. How can the risk of bugs slipping out in
production environment be reduced? Does these changes to the way of running
tests change the importance of quality metrics? Is it possible to automatically
measure quality metrics when tests are run continuously?\\
