Integration testing refers to the testing phase where several individual
units are tested together. Since units tests only assures that a single
unit works as expected, faults may still reside in how the units works
together.\\

\citet{book:adp} states that integration tests should be built
incrementally by extending unit tests so that they span over multiple
units. The scope of the tests is increased gradually, and both valid and
invalid data is given into the integration tested system unit in order
to test the interfaces between smaller units. Since this process is done
gradually, it is possible to see which parts of the integrated unit that
is faulty by examining which parts have been integrated since the latest
test run.\\

\citet{book:pfleeger} refers to this type of integration testing as
\emph{bottom-up testing}, since several low-level modules (modules at
the bottom level of the software) are integrated into higher-level
modules. Multiple other integration approaches such as \emph{top-down
testing} and \emph{sandwich testing} are also mentioned. The difference
between the approaches is in which order the units are integrated.\\

\citet{video:integrated_scam} criticizes one kind of integration tests,
which he refers to as \emph{integrated tests}. This refers to
integration tests that are testing the functionality of multiple units
in the same way as unit tests, i.e. by input data and examine the
output. When testing multiple units in this way, one loses the ability
to see which part of all the tested units that are actually failing. As
the number of tested units rises, the number of possible paths will grow
exponentially. This makes it hard to see the reason for a failed test,
but also makes it very hard to decide which of all this paths that needs
to be testes. Integrated tests therefore puts much less pressure on the
tested functions compared to unit tests.\\

\citeauthor{video:integrated_scam} claims that this fact makes
developers more sloppy, which increases the risk of introducing mistakes
that goes unnoticed through the test suite. If this is solved by writing
even more integration tests, developers have less time to do proper unit
tests and instead introduce more sloppy designs, forming an infinite
feedback-loop.\\

One may argue that this argument is based on the fact that integrated
tests to a large part are used instead of unit tests. The purpose of
integration tests are not to verify special cases of individual modules
but to make sure that they work together as intended. However, it would
be very hard to assure that all modules are working together by just
using a few test cases due to the number of possible execution paths.
The running time would also be long since large parts of the code base
needs to be run.\\

Instead of integrated tests, another type of integration tests are
proposed by \citeauthor{video:integrated_scam} called contract- and
collaboration tests. The purpose of these tests is to verify the
interface between all unit-tested modules by using mocks to test that
Unit A tries to invoke the expected methods on Unit B (contract test).
In order to avoid errors due to mocking, tests are also needed to make
sure that Unit B really responds to the calls that are expected to be
performed by Unit A in the contract test. The idea of this is to build a
chain of trust inside our own software via transitivity. This means that
if Unit A and Unit B works together as expected, and Unit B and Unit C
also works together as expected, Unit A and Unit C will also work
together as expected.\\
